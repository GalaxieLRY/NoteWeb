---
title: "N-gram"
date: 2025-07-16
draft: false
---

在自然语言处理（NLP）领域，N - gram是一种基于统计语言模型的文本表示方法。

+ **定义**：N - gram是指从一段文本中连续提取出的N个词（或字符，在字符级别的N - gram中）组成的序列。当N取不同值时，有不同的名称，比如：
    - 当N = 1时，称为unigram，即单个词或字符，例如“我”“你”“他”。
    - 当N = 2时，称为bigram，是由两个连续的词或字符组成的序列，例如“我 爱”“你 好”。
    - 当N = 3时，称为trigram，如“我 爱 你”“中 国 人”。
+ **原理**：N - gram模型基于这样一个假设，即一个词（或字符）出现的概率只与其前面有限个词（或字符）有关。通过统计大量文本中各种N - gram出现的频率，来估计一个特定N - gram在文本中出现的概率。例如，在一个大型语料库中统计“我 爱”这个bigram出现的次数，以及“我”这个词出现的总次数，就可以计算出在“我”出现的情况下，“爱”跟着出现的概率。
+ **应用**
    - **文本生成**：根据已有的N - gram概率分布，生成符合语法和语义规则的新文本。例如，给定一个起始词，通过查找对应的bigram或trigram概率，选择最可能的下一个词，逐步生成文本。
    - **语音识别**：将语音信号转换为文字时，利用N - gram模型可以帮助判断哪些词序列更有可能是正确的识别结果。例如，根据之前的语音识别结果和N - gram统计信息，选择最符合语言习惯的词来纠正识别错误。
    - **机器翻译**：在翻译过程中，N - gram可以用于评估目标语言中不同词序和短语组合的可能性，从而生成更自然流畅的翻译结果。
    - **拼写检查**：通过比较输入的文本与N - gram模型中存储的常见词序列，发现可能的拼写错误并进行纠正。例如，如果输入“hte”，根据unigram和bigram的统计信息，系统可能会建议纠正为“the”。
+ **优缺点**
    - **优点**：计算相对简单，容易实现，在许多NLP任务中能够取得较好的效果，尤其是对于处理局部的语言结构和短序列模式非常有效。
    - **缺点**：它假设每个N - gram是相互独立的，忽略了文本中的长期依赖关系和语义信息。例如，在处理具有复杂语法结构和语义关系的句子时，N - gram模型可能无法准确理解句子的整体含义。此外，N - gram模型需要大量的语料库来进行训练，以获取准确的统计信息，而且对于低频的N - gram，其统计结果可能不准确。

